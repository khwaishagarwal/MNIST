{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d86af640-2662-42a1-b2ab-ebfb1afc64cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (24.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e94e37d-417a-4ba5-86dc-cbc5f98d4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.9.6)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (6.0.0)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (16.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (2.32.3)\n",
      "Requirement already satisfied: simple-parsing in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (4.66.4)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: etils>=1.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.9.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.6.1)\n",
      "Requirement already satisfied: importlib_resources in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->tensorflow-datasets) (2024.7.4)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser~=0.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.63.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b98f9991-aa53-4599-9f1f-067b2b093514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf13a0d6-57a3-41e9-87e3-197a97d677d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in /opt/anaconda3/lib/python3.11/site-packages (4.9.6)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (14.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: simple-parsing in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (0.1.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: etils>=1.9.1 in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.9.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2023.10.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2024.6.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser~=0.15 in /opt/anaconda3/lib/python3.11/site-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.63.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/anaconda3/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install(\"tensorflow-datasets\")\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "835aad08-13da-4ffc-a471-78b077c11662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cac8f164-0c19-4435-8a2c-cd7d5a1e0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "393fddcd-9aef-4547-ac1b-44cbb71df4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image/=255.0\n",
    "    return image,label\n",
    "\n",
    "scaled_train_and_validation_data=mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a309503-9e52-4453-a780-55423adc2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE=10000\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e65f1d3-173f-4f57-9996-6d0c63bfaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data=shuffled_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08618cc9-c7cb-41c2-bb56-4110e5ce8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 14:06:21.426568: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=100\n",
    "train_data=train_data.batch(BATCH_SIZE)\n",
    "validation_data=validation_data.batch(num_validation_samples)\n",
    "test_data=test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fb95cb0-5683-49b2-9ab5-e03f6b818e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=784\n",
    "output_size=10\n",
    "hidden_layer_size=100\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax'),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ed6e50f-6bf6-4997-895b-12bd5eadd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a271b4f8-5c43-4eda-9694-1943c26f649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 1s - 2ms/step - accuracy: 0.9052 - loss: 0.3380 - val_accuracy: 0.9540 - val_loss: 0.1668\n",
      "Epoch 2/5\n",
      "540/540 - 1s - 1ms/step - accuracy: 0.9603 - loss: 0.1351 - val_accuracy: 0.9672 - val_loss: 0.1107\n",
      "Epoch 3/5\n",
      "540/540 - 1s - 1ms/step - accuracy: 0.9725 - loss: 0.0915 - val_accuracy: 0.9732 - val_loss: 0.0921\n",
      "Epoch 4/5\n",
      "540/540 - 1s - 1ms/step - accuracy: 0.9774 - loss: 0.0742 - val_accuracy: 0.9762 - val_loss: 0.0778\n",
      "Epoch 5/5\n",
      "540/540 - 1s - 1ms/step - accuracy: 0.9820 - loss: 0.0573 - val_accuracy: 0.9805 - val_loss: 0.0653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28d8c0f10>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "model.fit(train_data, \n",
    "          epochs=NUM_EPOCHS, \n",
    "          validation_data=(validation_inputs, validation_targets), \n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5dadd706-10b5-43fd-9b88-b2009045d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9750 - loss: 0.0799 \n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1bf498f-73cc-47d7-a796-6ad483810de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.08. Test accuracy: 97.51%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss : {0:.2f}. Test accuracy: {1:.2f}%\".format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bbe6c-9072-4ad6-b042-fdd5305170c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
